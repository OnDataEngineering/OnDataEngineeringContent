---
title: "Apache CarbonData"
description: "Unified storage solution for Hadoop based on an indexed columnar data format, focusing on providing efficient processing and querying capabilities for disparate data access patterns. Data is loaded in batch, encoded, indexed using multiple strategies, compressed and written to HDFS using a columnar file format. Provides a number of highly configurable indexes (multi-dimensional key, min/max index, and inverted index), global dictionary encoding and column grouping to support interactive style OLAP queries, high throughput scan queries, low latency point queries and individual record queries. Also supports batch updates and deletes using delta bitmap files and compaction. Written in Java using Apache Thrift, supports all common primitive data types and complex nested data types including array and structures. Consists of several modules, the format specification and core implementation (columnar storage, indexing, compression, encoding), Hadoop input/output format interface, deep integration with Spark, interfacing to Spark SQL and the DataFrame API and connectors for Hive and Presto. Started back in 2013 at Huawei's India R&D center, donated to the Apache Foundation in 2015, graduated in April 2017, with a stable (1.1.0) release in May 2017, and under active development."
alt-titles: [CarbonData]
vendors: [Apache]
type: "Commercial Open Source"
date: 2017-10-03
version: "1.2.0"
---
## Links

* <http://carbondata.apache.org> - CarbonData homepage
* <http://carbondata.apache.org/mainpage.html> - CarbonData documentation

## News

* <https://blogs.apache.org/carbondata> - CarbonData blog
* <https://github.com/apache/carbondata/releases> - details of releases
